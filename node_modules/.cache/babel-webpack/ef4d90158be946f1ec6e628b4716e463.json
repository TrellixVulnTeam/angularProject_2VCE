{"ast":null,"code":"'use strict';\n\nvar _regeneratorRuntime = require(\"/Users/abdillahihussein/Documents/GitHub/angularProject/node_modules/@babel/runtime/regenerator\");\n\nvar _createForOfIteratorHelper = require(\"/Users/abdillahihussein/Documents/GitHub/angularProject/node_modules/@babel/runtime/helpers/createForOfIteratorHelper\");\n\nvar _asyncToGenerator = require(\"/Users/abdillahihussein/Documents/GitHub/angularProject/node_modules/@babel/runtime/helpers/asyncToGenerator\");\n\nvar _classCallCheck = require(\"/Users/abdillahihussein/Documents/GitHub/angularProject/node_modules/@babel/runtime/helpers/classCallCheck\");\n\nvar _inherits = require(\"/Users/abdillahihussein/Documents/GitHub/angularProject/node_modules/@babel/runtime/helpers/inherits\");\n\nvar _createSuper = require(\"/Users/abdillahihussein/Documents/GitHub/angularProject/node_modules/@babel/runtime/helpers/createSuper\");\n\nvar _wrapNativeSuper = require(\"/Users/abdillahihussein/Documents/GitHub/angularProject/node_modules/@babel/runtime/helpers/wrapNativeSuper\");\n\nvar util = require('util');\n\nvar crypto = require('crypto');\n\nvar fs = require('fs');\n\nvar Minipass = require('minipass');\n\nvar path = require('path');\n\nvar ssri = require('ssri');\n\nvar uniqueFilename = require('unique-filename');\n\nvar _require = require('./util/disposer'),\n    disposer = _require.disposer;\n\nvar contentPath = require('./content/path');\n\nvar fixOwner = require('./util/fix-owner');\n\nvar hashToSegments = require('./util/hash-to-segments');\n\nvar indexV = require('../package.json')['cache-version'].index;\n\nvar moveFile = require('@npmcli/move-file');\n\nvar _rimraf = require('rimraf');\n\nvar rimraf = util.promisify(_rimraf);\nrimraf.sync = _rimraf.sync;\nvar appendFile = util.promisify(fs.appendFile);\nvar readFile = util.promisify(fs.readFile);\nvar readdir = util.promisify(fs.readdir);\nvar writeFile = util.promisify(fs.writeFile);\n\nmodule.exports.NotFoundError = /*#__PURE__*/function (_Error) {\n  _inherits(NotFoundError, _Error);\n\n  var _super = _createSuper(NotFoundError);\n\n  function NotFoundError(cache, key) {\n    var _this;\n\n    _classCallCheck(this, NotFoundError);\n\n    _this = _super.call(this, \"No cache entry for \".concat(key, \" found in \").concat(cache));\n    _this.code = 'ENOENT';\n    _this.cache = cache;\n    _this.key = key;\n    return _this;\n  }\n\n  return NotFoundError;\n}( /*#__PURE__*/_wrapNativeSuper(Error));\n\nmodule.exports.compact = compact;\n\nfunction compact(_x, _x2, _x3) {\n  return _compact.apply(this, arguments);\n}\n\nfunction _compact() {\n  _compact = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4(cache, key, matchFn) {\n    var opts,\n        bucket,\n        entries,\n        newEntries,\n        _loop,\n        i,\n        _ret,\n        newIndex,\n        setup,\n        teardown,\n        write,\n        _args4 = arguments;\n\n    return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n      while (1) {\n        switch (_context4.prev = _context4.next) {\n          case 0:\n            opts = _args4.length > 3 && _args4[3] !== undefined ? _args4[3] : {};\n            bucket = bucketPath(cache, key);\n            _context4.next = 4;\n            return bucketEntries(bucket);\n\n          case 4:\n            entries = _context4.sent;\n            newEntries = []; // we loop backwards because the bottom-most result is the newest\n            // since we add new entries with appendFile\n\n            _loop = function _loop(i) {\n              var entry = entries[i]; // a null integrity could mean either a delete was appended\n              // or the user has simply stored an index that does not map\n              // to any content. we determine if the user wants to keep the\n              // null integrity based on the validateEntry function passed in options.\n              // if the integrity is null and no validateEntry is provided, we break\n              // as we consider the null integrity to be a deletion of everything\n              // that came before it.\n\n              if (entry.integrity === null && !opts.validateEntry) return \"break\"; // if this entry is valid, and it is either the first entry or\n              // the newEntries array doesn't already include an entry that\n              // matches this one based on the provided matchFn, then we add\n              // it to the beginning of our list\n\n              if ((!opts.validateEntry || opts.validateEntry(entry) === true) && (newEntries.length === 0 || !newEntries.find(function (oldEntry) {\n                return matchFn(oldEntry, entry);\n              }))) newEntries.unshift(entry);\n            };\n\n            i = entries.length - 1;\n\n          case 8:\n            if (!(i >= 0)) {\n              _context4.next = 15;\n              break;\n            }\n\n            _ret = _loop(i);\n\n            if (!(_ret === \"break\")) {\n              _context4.next = 12;\n              break;\n            }\n\n            return _context4.abrupt(\"break\", 15);\n\n          case 12:\n            --i;\n            _context4.next = 8;\n            break;\n\n          case 15:\n            newIndex = '\\n' + newEntries.map(function (entry) {\n              var stringified = JSON.stringify(entry);\n              var hash = hashEntry(stringified);\n              return \"\".concat(hash, \"\\t\").concat(stringified);\n            }).join('\\n');\n\n            setup = /*#__PURE__*/function () {\n              var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n                var target;\n                return _regeneratorRuntime.wrap(function _callee$(_context) {\n                  while (1) {\n                    switch (_context.prev = _context.next) {\n                      case 0:\n                        target = uniqueFilename(path.join(cache, 'tmp'), opts.tmpPrefix);\n                        _context.next = 3;\n                        return fixOwner.mkdirfix(cache, path.dirname(target));\n\n                      case 3:\n                        return _context.abrupt(\"return\", {\n                          target: target,\n                          moved: false\n                        });\n\n                      case 4:\n                      case \"end\":\n                        return _context.stop();\n                    }\n                  }\n                }, _callee);\n              }));\n\n              return function setup() {\n                return _ref.apply(this, arguments);\n              };\n            }();\n\n            teardown = /*#__PURE__*/function () {\n              var _ref2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(tmp) {\n                return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n                  while (1) {\n                    switch (_context2.prev = _context2.next) {\n                      case 0:\n                        if (tmp.moved) {\n                          _context2.next = 2;\n                          break;\n                        }\n\n                        return _context2.abrupt(\"return\", rimraf(tmp.target));\n\n                      case 2:\n                      case \"end\":\n                        return _context2.stop();\n                    }\n                  }\n                }, _callee2);\n              }));\n\n              return function teardown(_x4) {\n                return _ref2.apply(this, arguments);\n              };\n            }();\n\n            write = /*#__PURE__*/function () {\n              var _ref3 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(tmp) {\n                return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n                  while (1) {\n                    switch (_context3.prev = _context3.next) {\n                      case 0:\n                        _context3.next = 2;\n                        return writeFile(tmp.target, newIndex, {\n                          flag: 'wx'\n                        });\n\n                      case 2:\n                        _context3.next = 4;\n                        return fixOwner.mkdirfix(cache, path.dirname(bucket));\n\n                      case 4:\n                        _context3.next = 6;\n                        return moveFile(tmp.target, bucket);\n\n                      case 6:\n                        tmp.moved = true;\n                        _context3.prev = 7;\n                        _context3.next = 10;\n                        return fixOwner.chownr(cache, bucket);\n\n                      case 10:\n                        _context3.next = 16;\n                        break;\n\n                      case 12:\n                        _context3.prev = 12;\n                        _context3.t0 = _context3[\"catch\"](7);\n\n                        if (!(_context3.t0.code !== 'ENOENT')) {\n                          _context3.next = 16;\n                          break;\n                        }\n\n                        throw _context3.t0;\n\n                      case 16:\n                      case \"end\":\n                        return _context3.stop();\n                    }\n                  }\n                }, _callee3, null, [[7, 12]]);\n              }));\n\n              return function write(_x5) {\n                return _ref3.apply(this, arguments);\n              };\n            }(); // write the file atomically\n\n\n            _context4.next = 21;\n            return disposer(setup(), teardown, write);\n\n          case 21:\n            return _context4.abrupt(\"return\", newEntries.reverse().map(function (entry) {\n              return formatEntry(cache, entry, true);\n            }));\n\n          case 22:\n          case \"end\":\n            return _context4.stop();\n        }\n      }\n    }, _callee4);\n  }));\n  return _compact.apply(this, arguments);\n}\n\nmodule.exports.insert = insert;\n\nfunction insert(cache, key, integrity) {\n  var opts = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n  var metadata = opts.metadata,\n      size = opts.size;\n  var bucket = bucketPath(cache, key);\n  var entry = {\n    key: key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size: size,\n    metadata: metadata\n  };\n  return fixOwner.mkdirfix(cache, path.dirname(bucket)).then(function () {\n    var stringified = JSON.stringify(entry); // NOTE - Cleverness ahoy!\n    //\n    // This works because it's tremendously unlikely for an entry to corrupt\n    // another while still preserving the string length of the JSON in\n    // question. So, we just slap the length in there and verify it on read.\n    //\n    // Thanks to @isaacs for the whiteboarding session that ended up with\n    // this.\n\n    return appendFile(bucket, \"\\n\".concat(hashEntry(stringified), \"\\t\").concat(stringified));\n  }).then(function () {\n    return fixOwner.chownr(cache, bucket);\n  }).catch(function (err) {\n    if (err.code === 'ENOENT') return undefined;\n    throw err; // There's a class of race conditions that happen when things get deleted\n    // during fixOwner, or between the two mkdirfix/chownr calls.\n    //\n    // It's perfectly fine to just not bother in those cases and lie\n    // that the index entry was written. Because it's a cache.\n  }).then(function () {\n    return formatEntry(cache, entry);\n  });\n}\n\nmodule.exports.insert.sync = insertSync;\n\nfunction insertSync(cache, key, integrity) {\n  var opts = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n  var metadata = opts.metadata,\n      size = opts.size;\n  var bucket = bucketPath(cache, key);\n  var entry = {\n    key: key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size: size,\n    metadata: metadata\n  };\n  fixOwner.mkdirfix.sync(cache, path.dirname(bucket));\n  var stringified = JSON.stringify(entry);\n  fs.appendFileSync(bucket, \"\\n\".concat(hashEntry(stringified), \"\\t\").concat(stringified));\n\n  try {\n    fixOwner.chownr.sync(cache, bucket);\n  } catch (err) {\n    if (err.code !== 'ENOENT') throw err;\n  }\n\n  return formatEntry(cache, entry);\n}\n\nmodule.exports.find = find;\n\nfunction find(cache, key) {\n  var bucket = bucketPath(cache, key);\n  return bucketEntries(bucket).then(function (entries) {\n    return entries.reduce(function (latest, next) {\n      if (next && next.key === key) return formatEntry(cache, next);else return latest;\n    }, null);\n  }).catch(function (err) {\n    if (err.code === 'ENOENT') return null;else throw err;\n  });\n}\n\nmodule.exports.find.sync = findSync;\n\nfunction findSync(cache, key) {\n  var bucket = bucketPath(cache, key);\n\n  try {\n    return bucketEntriesSync(bucket).reduce(function (latest, next) {\n      if (next && next.key === key) return formatEntry(cache, next);else return latest;\n    }, null);\n  } catch (err) {\n    if (err.code === 'ENOENT') return null;else throw err;\n  }\n}\n\nmodule.exports.delete = del;\n\nfunction del(cache, key) {\n  var opts = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  if (!opts.removeFully) return insert(cache, key, null, opts);\n  var bucket = bucketPath(cache, key);\n  return rimraf(bucket);\n}\n\nmodule.exports.delete.sync = delSync;\n\nfunction delSync(cache, key) {\n  var opts = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  if (!opts.removeFully) return insertSync(cache, key, null, opts);\n  var bucket = bucketPath(cache, key);\n  return rimraf.sync(bucket);\n}\n\nmodule.exports.lsStream = lsStream;\n\nfunction lsStream(cache) {\n  var indexDir = bucketDir(cache);\n  var stream = new Minipass({\n    objectMode: true\n  });\n  readdirOrEmpty(indexDir).then(function (buckets) {\n    return Promise.all(buckets.map(function (bucket) {\n      var bucketPath = path.join(indexDir, bucket);\n      return readdirOrEmpty(bucketPath).then(function (subbuckets) {\n        return Promise.all(subbuckets.map(function (subbucket) {\n          var subbucketPath = path.join(bucketPath, subbucket); // \"/cachename/<bucket 0xFF>/<bucket 0xFF>./*\"\n\n          return readdirOrEmpty(subbucketPath).then(function (entries) {\n            return Promise.all(entries.map(function (entry) {\n              var entryPath = path.join(subbucketPath, entry);\n              return bucketEntries(entryPath).then(function (entries) {\n                return (// using a Map here prevents duplicate keys from\n                  // showing up twice, I guess?\n                  entries.reduce(function (acc, entry) {\n                    acc.set(entry.key, entry);\n                    return acc;\n                  }, new Map())\n                );\n              }).then(function (reduced) {\n                // reduced is a map of key => entry\n                var _iterator = _createForOfIteratorHelper(reduced.values()),\n                    _step;\n\n                try {\n                  for (_iterator.s(); !(_step = _iterator.n()).done;) {\n                    var _entry = _step.value;\n                    var formatted = formatEntry(cache, _entry);\n                    if (formatted) stream.write(formatted);\n                  }\n                } catch (err) {\n                  _iterator.e(err);\n                } finally {\n                  _iterator.f();\n                }\n              }).catch(function (err) {\n                if (err.code === 'ENOENT') return undefined;\n                throw err;\n              });\n            }));\n          });\n        }));\n      });\n    }));\n  }).then(function () {\n    return stream.end();\n  }, function (err) {\n    return stream.emit('error', err);\n  });\n  return stream;\n}\n\nmodule.exports.ls = ls;\n\nfunction ls(cache) {\n  return lsStream(cache).collect().then(function (entries) {\n    return entries.reduce(function (acc, xs) {\n      acc[xs.key] = xs;\n      return acc;\n    }, {});\n  });\n}\n\nmodule.exports.bucketEntries = bucketEntries;\n\nfunction bucketEntries(bucket, filter) {\n  return readFile(bucket, 'utf8').then(function (data) {\n    return _bucketEntries(data, filter);\n  });\n}\n\nmodule.exports.bucketEntries.sync = bucketEntriesSync;\n\nfunction bucketEntriesSync(bucket, filter) {\n  var data = fs.readFileSync(bucket, 'utf8');\n  return _bucketEntries(data, filter);\n}\n\nfunction _bucketEntries(data, filter) {\n  var entries = [];\n  data.split('\\n').forEach(function (entry) {\n    if (!entry) return;\n    var pieces = entry.split('\\t');\n\n    if (!pieces[1] || hashEntry(pieces[1]) !== pieces[0]) {\n      // Hash is no good! Corruption or malice? Doesn't matter!\n      // EJECT EJECT\n      return;\n    }\n\n    var obj;\n\n    try {\n      obj = JSON.parse(pieces[1]);\n    } catch (e) {\n      // Entry is corrupted!\n      return;\n    }\n\n    if (obj) entries.push(obj);\n  });\n  return entries;\n}\n\nmodule.exports.bucketDir = bucketDir;\n\nfunction bucketDir(cache) {\n  return path.join(cache, \"index-v\".concat(indexV));\n}\n\nmodule.exports.bucketPath = bucketPath;\n\nfunction bucketPath(cache, key) {\n  var hashed = hashKey(key);\n  return path.join.apply(path, [bucketDir(cache)].concat(hashToSegments(hashed)));\n}\n\nmodule.exports.hashKey = hashKey;\n\nfunction hashKey(key) {\n  return hash(key, 'sha256');\n}\n\nmodule.exports.hashEntry = hashEntry;\n\nfunction hashEntry(str) {\n  return hash(str, 'sha1');\n}\n\nfunction hash(str, digest) {\n  return crypto.createHash(digest).update(str).digest('hex');\n}\n\nfunction formatEntry(cache, entry, keepAll) {\n  // Treat null digests as deletions. They'll shadow any previous entries.\n  if (!entry.integrity && !keepAll) return null;\n  return {\n    key: entry.key,\n    integrity: entry.integrity,\n    path: entry.integrity ? contentPath(cache, entry.integrity) : undefined,\n    size: entry.size,\n    time: entry.time,\n    metadata: entry.metadata\n  };\n}\n\nfunction readdirOrEmpty(dir) {\n  return readdir(dir).catch(function (err) {\n    if (err.code === 'ENOENT' || err.code === 'ENOTDIR') return [];\n    throw err;\n  });\n}","map":{"version":3,"sources":["/Users/abdillahihussein/Documents/GitHub/angularProject/node_modules/cacache/lib/entry-index.js"],"names":["util","require","crypto","fs","Minipass","path","ssri","uniqueFilename","disposer","contentPath","fixOwner","hashToSegments","indexV","index","moveFile","_rimraf","rimraf","promisify","sync","appendFile","readFile","readdir","writeFile","module","exports","NotFoundError","cache","key","code","Error","compact","matchFn","opts","bucket","bucketPath","bucketEntries","entries","newEntries","i","entry","integrity","validateEntry","length","find","oldEntry","unshift","newIndex","map","stringified","JSON","stringify","hash","hashEntry","join","setup","target","tmpPrefix","mkdirfix","dirname","moved","teardown","tmp","write","flag","chownr","reverse","formatEntry","insert","metadata","size","time","Date","now","then","catch","err","undefined","insertSync","appendFileSync","reduce","latest","next","findSync","bucketEntriesSync","delete","del","removeFully","delSync","lsStream","indexDir","bucketDir","stream","objectMode","readdirOrEmpty","buckets","Promise","all","subbuckets","subbucket","subbucketPath","entryPath","acc","set","Map","reduced","values","formatted","end","emit","ls","collect","xs","filter","data","_bucketEntries","readFileSync","split","forEach","pieces","obj","parse","e","push","hashed","hashKey","apply","concat","str","digest","createHash","update","keepAll","dir"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAEA,IAAMA,IAAI,GAAGC,OAAO,CAAC,MAAD,CAApB;;AACA,IAAMC,MAAM,GAAGD,OAAO,CAAC,QAAD,CAAtB;;AACA,IAAME,EAAE,GAAGF,OAAO,CAAC,IAAD,CAAlB;;AACA,IAAMG,QAAQ,GAAGH,OAAO,CAAC,UAAD,CAAxB;;AACA,IAAMI,IAAI,GAAGJ,OAAO,CAAC,MAAD,CAApB;;AACA,IAAMK,IAAI,GAAGL,OAAO,CAAC,MAAD,CAApB;;AACA,IAAMM,cAAc,GAAGN,OAAO,CAAC,iBAAD,CAA9B;;AAEA,eAAqBA,OAAO,CAAC,iBAAD,CAA5B;AAAA,IAAQO,QAAR,YAAQA,QAAR;;AACA,IAAMC,WAAW,GAAGR,OAAO,CAAC,gBAAD,CAA3B;;AACA,IAAMS,QAAQ,GAAGT,OAAO,CAAC,kBAAD,CAAxB;;AACA,IAAMU,cAAc,GAAGV,OAAO,CAAC,yBAAD,CAA9B;;AACA,IAAMW,MAAM,GAAGX,OAAO,CAAC,iBAAD,CAAP,CAA2B,eAA3B,EAA4CY,KAA3D;;AACA,IAAMC,QAAQ,GAAGb,OAAO,CAAC,mBAAD,CAAxB;;AACA,IAAMc,OAAO,GAAGd,OAAO,CAAC,QAAD,CAAvB;;AACA,IAAMe,MAAM,GAAGhB,IAAI,CAACiB,SAAL,CAAeF,OAAf,CAAf;AACAC,MAAM,CAACE,IAAP,GAAcH,OAAO,CAACG,IAAtB;AAEA,IAAMC,UAAU,GAAGnB,IAAI,CAACiB,SAAL,CAAed,EAAE,CAACgB,UAAlB,CAAnB;AACA,IAAMC,QAAQ,GAAGpB,IAAI,CAACiB,SAAL,CAAed,EAAE,CAACiB,QAAlB,CAAjB;AACA,IAAMC,OAAO,GAAGrB,IAAI,CAACiB,SAAL,CAAed,EAAE,CAACkB,OAAlB,CAAhB;AACA,IAAMC,SAAS,GAAGtB,IAAI,CAACiB,SAAL,CAAed,EAAE,CAACmB,SAAlB,CAAlB;;AAEAC,MAAM,CAACC,OAAP,CAAeC,aAAf;AAAA;;AAAA;;AACE,yBAAaC,KAAb,EAAoBC,GAApB,EAAyB;AAAA;;AAAA;;AACvB,2DAA4BA,GAA5B,uBAA4CD,KAA5C;AACA,UAAKE,IAAL,GAAY,QAAZ;AACA,UAAKF,KAAL,GAAaA,KAAb;AACA,UAAKC,GAAL,GAAWA,GAAX;AAJuB;AAKxB;;AANH;AAAA,iCAA2DE,KAA3D;;AASAN,MAAM,CAACC,OAAP,CAAeM,OAAf,GAAyBA,OAAzB;;SAEeA,O;;;;;sEAAf,kBAAwBJ,KAAxB,EAA+BC,GAA/B,EAAoCI,OAApC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAA6CC,YAAAA,IAA7C,8DAAoD,EAApD;AACQC,YAAAA,MADR,GACiBC,UAAU,CAACR,KAAD,EAAQC,GAAR,CAD3B;AAAA;AAAA,mBAEwBQ,aAAa,CAACF,MAAD,CAFrC;;AAAA;AAEQG,YAAAA,OAFR;AAGQC,YAAAA,UAHR,GAGqB,EAHrB,EAIE;AACA;;AALF,mCAMWC,CANX;AAOI,kBAAMC,KAAK,GAAGH,OAAO,CAACE,CAAD,CAArB,CAPJ,CAQI;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,kBAAIC,KAAK,CAACC,SAAN,KAAoB,IAApB,IAA4B,CAACR,IAAI,CAACS,aAAtC,EACE,eAhBN,CAkBI;AACA;AACA;AACA;;AACA,kBAAI,CAAC,CAACT,IAAI,CAACS,aAAN,IAAuBT,IAAI,CAACS,aAAL,CAAmBF,KAAnB,MAA8B,IAAtD,MACDF,UAAU,CAACK,MAAX,KAAsB,CAAtB,IACC,CAACL,UAAU,CAACM,IAAX,CAAgB,UAACC,QAAD;AAAA,uBAAcb,OAAO,CAACa,QAAD,EAAWL,KAAX,CAArB;AAAA,eAAhB,CAFD,CAAJ,EAGEF,UAAU,CAACQ,OAAX,CAAmBN,KAAnB;AAzBN;;AAMWD,YAAAA,CANX,GAMeF,OAAO,CAACM,MAAR,GAAiB,CANhC;;AAAA;AAAA,kBAMmCJ,CAAC,IAAI,CANxC;AAAA;AAAA;AAAA;;AAAA,yBAMWA,CANX;;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAM2C,cAAEA,CAN7C;AAAA;AAAA;;AAAA;AA4BQQ,YAAAA,QA5BR,GA4BmB,OAAOT,UAAU,CAACU,GAAX,CAAe,UAACR,KAAD,EAAW;AAChD,kBAAMS,WAAW,GAAGC,IAAI,CAACC,SAAL,CAAeX,KAAf,CAApB;AACA,kBAAMY,IAAI,GAAGC,SAAS,CAACJ,WAAD,CAAtB;AACA,+BAAUG,IAAV,eAAmBH,WAAnB;AACD,aAJuB,EAIrBK,IAJqB,CAIhB,IAJgB,CA5B1B;;AAkCQC,YAAAA,KAlCR;AAAA,kFAkCgB;AAAA;AAAA;AAAA;AAAA;AAAA;AACNC,wBAAAA,MADM,GACGhD,cAAc,CAACF,IAAI,CAACgD,IAAL,CAAU3B,KAAV,EAAiB,KAAjB,CAAD,EAA0BM,IAAI,CAACwB,SAA/B,CADjB;AAAA;AAAA,+BAEN9C,QAAQ,CAAC+C,QAAT,CAAkB/B,KAAlB,EAAyBrB,IAAI,CAACqD,OAAL,CAAaH,MAAb,CAAzB,CAFM;;AAAA;AAAA,yDAGL;AACLA,0BAAAA,MAAM,EAANA,MADK;AAELI,0BAAAA,KAAK,EAAE;AAFF,yBAHK;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,eAlChB;;AAAA,8BAkCQL,KAlCR;AAAA;AAAA;AAAA;;AA2CQM,YAAAA,QA3CR;AAAA,mFA2CmB,kBAAOC,GAAP;AAAA;AAAA;AAAA;AAAA;AAAA,4BACVA,GAAG,CAACF,KADM;AAAA;AAAA;AAAA;;AAAA,0DAEN3C,MAAM,CAAC6C,GAAG,CAACN,MAAL,CAFA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,eA3CnB;;AAAA,8BA2CQK,QA3CR;AAAA;AAAA;AAAA;;AAgDQE,YAAAA,KAhDR;AAAA,mFAgDgB,kBAAOD,GAAP;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,+BACNvC,SAAS,CAACuC,GAAG,CAACN,MAAL,EAAaT,QAAb,EAAuB;AAAEiB,0BAAAA,IAAI,EAAE;AAAR,yBAAvB,CADH;;AAAA;AAAA;AAAA,+BAENrD,QAAQ,CAAC+C,QAAT,CAAkB/B,KAAlB,EAAyBrB,IAAI,CAACqD,OAAL,CAAazB,MAAb,CAAzB,CAFM;;AAAA;AAAA;AAAA,+BAKNnB,QAAQ,CAAC+C,GAAG,CAACN,MAAL,EAAatB,MAAb,CALF;;AAAA;AAMZ4B,wBAAAA,GAAG,CAACF,KAAJ,GAAY,IAAZ;AANY;AAAA;AAAA,+BAQJjD,QAAQ,CAACsD,MAAT,CAAgBtC,KAAhB,EAAuBO,MAAvB,CARI;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA,8BAUN,aAAIL,IAAJ,KAAa,QAVP;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,eAhDhB;;AAAA,8BAgDQkC,KAhDR;AAAA;AAAA;AAAA,iBA+DE;;;AA/DF;AAAA,mBAgEQtD,QAAQ,CAAC8C,KAAK,EAAN,EAAUM,QAAV,EAAoBE,KAApB,CAhEhB;;AAAA;AAAA,8CAuESzB,UAAU,CAAC4B,OAAX,GAAqBlB,GAArB,CAAyB,UAACR,KAAD;AAAA,qBAAW2B,WAAW,CAACxC,KAAD,EAAQa,KAAR,EAAe,IAAf,CAAtB;AAAA,aAAzB,CAvET;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,G;;;;AA0EAhB,MAAM,CAACC,OAAP,CAAe2C,MAAf,GAAwBA,MAAxB;;AAEA,SAASA,MAAT,CAAiBzC,KAAjB,EAAwBC,GAAxB,EAA6Ba,SAA7B,EAAmD;AAAA,MAAXR,IAAW,uEAAJ,EAAI;AACjD,MAAQoC,QAAR,GAA2BpC,IAA3B,CAAQoC,QAAR;AAAA,MAAkBC,IAAlB,GAA2BrC,IAA3B,CAAkBqC,IAAlB;AACA,MAAMpC,MAAM,GAAGC,UAAU,CAACR,KAAD,EAAQC,GAAR,CAAzB;AACA,MAAMY,KAAK,GAAG;AACZZ,IAAAA,GAAG,EAAHA,GADY;AAEZa,IAAAA,SAAS,EAAEA,SAAS,IAAIlC,IAAI,CAAC4C,SAAL,CAAeV,SAAf,CAFZ;AAGZ8B,IAAAA,IAAI,EAAEC,IAAI,CAACC,GAAL,EAHM;AAIZH,IAAAA,IAAI,EAAJA,IAJY;AAKZD,IAAAA,QAAQ,EAARA;AALY,GAAd;AAOA,SAAO1D,QAAQ,CACZ+C,QADI,CACK/B,KADL,EACYrB,IAAI,CAACqD,OAAL,CAAazB,MAAb,CADZ,EAEJwC,IAFI,CAEC,YAAM;AACV,QAAMzB,WAAW,GAAGC,IAAI,CAACC,SAAL,CAAeX,KAAf,CAApB,CADU,CAEV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,WAAOpB,UAAU,CAACc,MAAD,cAAcmB,SAAS,CAACJ,WAAD,CAAvB,eAAyCA,WAAzC,EAAjB;AACD,GAbI,EAcJyB,IAdI,CAcC;AAAA,WAAM/D,QAAQ,CAACsD,MAAT,CAAgBtC,KAAhB,EAAuBO,MAAvB,CAAN;AAAA,GAdD,EAeJyC,KAfI,CAeE,UAACC,GAAD,EAAS;AACd,QAAIA,GAAG,CAAC/C,IAAJ,KAAa,QAAjB,EACE,OAAOgD,SAAP;AAEF,UAAMD,GAAN,CAJc,CAKd;AACA;AACA;AACA;AACA;AACD,GAzBI,EA0BJF,IA1BI,CA0BC,YAAM;AACV,WAAOP,WAAW,CAACxC,KAAD,EAAQa,KAAR,CAAlB;AACD,GA5BI,CAAP;AA6BD;;AAEDhB,MAAM,CAACC,OAAP,CAAe2C,MAAf,CAAsBjD,IAAtB,GAA6B2D,UAA7B;;AAEA,SAASA,UAAT,CAAqBnD,KAArB,EAA4BC,GAA5B,EAAiCa,SAAjC,EAAuD;AAAA,MAAXR,IAAW,uEAAJ,EAAI;AACrD,MAAQoC,QAAR,GAA2BpC,IAA3B,CAAQoC,QAAR;AAAA,MAAkBC,IAAlB,GAA2BrC,IAA3B,CAAkBqC,IAAlB;AACA,MAAMpC,MAAM,GAAGC,UAAU,CAACR,KAAD,EAAQC,GAAR,CAAzB;AACA,MAAMY,KAAK,GAAG;AACZZ,IAAAA,GAAG,EAAHA,GADY;AAEZa,IAAAA,SAAS,EAAEA,SAAS,IAAIlC,IAAI,CAAC4C,SAAL,CAAeV,SAAf,CAFZ;AAGZ8B,IAAAA,IAAI,EAAEC,IAAI,CAACC,GAAL,EAHM;AAIZH,IAAAA,IAAI,EAAJA,IAJY;AAKZD,IAAAA,QAAQ,EAARA;AALY,GAAd;AAOA1D,EAAAA,QAAQ,CAAC+C,QAAT,CAAkBvC,IAAlB,CAAuBQ,KAAvB,EAA8BrB,IAAI,CAACqD,OAAL,CAAazB,MAAb,CAA9B;AACA,MAAMe,WAAW,GAAGC,IAAI,CAACC,SAAL,CAAeX,KAAf,CAApB;AACApC,EAAAA,EAAE,CAAC2E,cAAH,CAAkB7C,MAAlB,cAA+BmB,SAAS,CAACJ,WAAD,CAAxC,eAA0DA,WAA1D;;AACA,MAAI;AACFtC,IAAAA,QAAQ,CAACsD,MAAT,CAAgB9C,IAAhB,CAAqBQ,KAArB,EAA4BO,MAA5B;AACD,GAFD,CAEE,OAAO0C,GAAP,EAAY;AACZ,QAAIA,GAAG,CAAC/C,IAAJ,KAAa,QAAjB,EACE,MAAM+C,GAAN;AACH;;AACD,SAAOT,WAAW,CAACxC,KAAD,EAAQa,KAAR,CAAlB;AACD;;AAEDhB,MAAM,CAACC,OAAP,CAAemB,IAAf,GAAsBA,IAAtB;;AAEA,SAASA,IAAT,CAAejB,KAAf,EAAsBC,GAAtB,EAA2B;AACzB,MAAMM,MAAM,GAAGC,UAAU,CAACR,KAAD,EAAQC,GAAR,CAAzB;AACA,SAAOQ,aAAa,CAACF,MAAD,CAAb,CACJwC,IADI,CACC,UAACrC,OAAD,EAAa;AACjB,WAAOA,OAAO,CAAC2C,MAAR,CAAe,UAACC,MAAD,EAASC,IAAT,EAAkB;AACtC,UAAIA,IAAI,IAAIA,IAAI,CAACtD,GAAL,KAAaA,GAAzB,EACE,OAAOuC,WAAW,CAACxC,KAAD,EAAQuD,IAAR,CAAlB,CADF,KAGE,OAAOD,MAAP;AACH,KALM,EAKJ,IALI,CAAP;AAMD,GARI,EASJN,KATI,CASE,UAACC,GAAD,EAAS;AACd,QAAIA,GAAG,CAAC/C,IAAJ,KAAa,QAAjB,EACE,OAAO,IAAP,CADF,KAGE,MAAM+C,GAAN;AACH,GAdI,CAAP;AAeD;;AAEDpD,MAAM,CAACC,OAAP,CAAemB,IAAf,CAAoBzB,IAApB,GAA2BgE,QAA3B;;AAEA,SAASA,QAAT,CAAmBxD,KAAnB,EAA0BC,GAA1B,EAA+B;AAC7B,MAAMM,MAAM,GAAGC,UAAU,CAACR,KAAD,EAAQC,GAAR,CAAzB;;AACA,MAAI;AACF,WAAOwD,iBAAiB,CAAClD,MAAD,CAAjB,CAA0B8C,MAA1B,CAAiC,UAACC,MAAD,EAASC,IAAT,EAAkB;AACxD,UAAIA,IAAI,IAAIA,IAAI,CAACtD,GAAL,KAAaA,GAAzB,EACE,OAAOuC,WAAW,CAACxC,KAAD,EAAQuD,IAAR,CAAlB,CADF,KAGE,OAAOD,MAAP;AACH,KALM,EAKJ,IALI,CAAP;AAMD,GAPD,CAOE,OAAOL,GAAP,EAAY;AACZ,QAAIA,GAAG,CAAC/C,IAAJ,KAAa,QAAjB,EACE,OAAO,IAAP,CADF,KAGE,MAAM+C,GAAN;AACH;AACF;;AAEDpD,MAAM,CAACC,OAAP,CAAe4D,MAAf,GAAwBC,GAAxB;;AAEA,SAASA,GAAT,CAAc3D,KAAd,EAAqBC,GAArB,EAAqC;AAAA,MAAXK,IAAW,uEAAJ,EAAI;AACnC,MAAI,CAACA,IAAI,CAACsD,WAAV,EACE,OAAOnB,MAAM,CAACzC,KAAD,EAAQC,GAAR,EAAa,IAAb,EAAmBK,IAAnB,CAAb;AAEF,MAAMC,MAAM,GAAGC,UAAU,CAACR,KAAD,EAAQC,GAAR,CAAzB;AACA,SAAOX,MAAM,CAACiB,MAAD,CAAb;AACD;;AAEDV,MAAM,CAACC,OAAP,CAAe4D,MAAf,CAAsBlE,IAAtB,GAA6BqE,OAA7B;;AAEA,SAASA,OAAT,CAAkB7D,KAAlB,EAAyBC,GAAzB,EAAyC;AAAA,MAAXK,IAAW,uEAAJ,EAAI;AACvC,MAAI,CAACA,IAAI,CAACsD,WAAV,EACE,OAAOT,UAAU,CAACnD,KAAD,EAAQC,GAAR,EAAa,IAAb,EAAmBK,IAAnB,CAAjB;AAEF,MAAMC,MAAM,GAAGC,UAAU,CAACR,KAAD,EAAQC,GAAR,CAAzB;AACA,SAAOX,MAAM,CAACE,IAAP,CAAYe,MAAZ,CAAP;AACD;;AAEDV,MAAM,CAACC,OAAP,CAAegE,QAAf,GAA0BA,QAA1B;;AAEA,SAASA,QAAT,CAAmB9D,KAAnB,EAA0B;AACxB,MAAM+D,QAAQ,GAAGC,SAAS,CAAChE,KAAD,CAA1B;AACA,MAAMiE,MAAM,GAAG,IAAIvF,QAAJ,CAAa;AAAEwF,IAAAA,UAAU,EAAE;AAAd,GAAb,CAAf;AAEAC,EAAAA,cAAc,CAACJ,QAAD,CAAd,CAAyBhB,IAAzB,CAA8B,UAAAqB,OAAO;AAAA,WAAIC,OAAO,CAACC,GAAR,CACvCF,OAAO,CAAC/C,GAAR,CAAY,UAAAd,MAAM,EAAI;AACpB,UAAMC,UAAU,GAAG7B,IAAI,CAACgD,IAAL,CAAUoC,QAAV,EAAoBxD,MAApB,CAAnB;AACA,aAAO4D,cAAc,CAAC3D,UAAD,CAAd,CAA2BuC,IAA3B,CAAgC,UAAAwB,UAAU;AAAA,eAAIF,OAAO,CAACC,GAAR,CACnDC,UAAU,CAAClD,GAAX,CAAe,UAAAmD,SAAS,EAAI;AAC1B,cAAMC,aAAa,GAAG9F,IAAI,CAACgD,IAAL,CAAUnB,UAAV,EAAsBgE,SAAtB,CAAtB,CAD0B,CAG1B;;AACA,iBAAOL,cAAc,CAACM,aAAD,CAAd,CAA8B1B,IAA9B,CAAmC,UAAArC,OAAO;AAAA,mBAAI2D,OAAO,CAACC,GAAR,CACnD5D,OAAO,CAACW,GAAR,CAAY,UAAAR,KAAK,EAAI;AACnB,kBAAM6D,SAAS,GAAG/F,IAAI,CAACgD,IAAL,CAAU8C,aAAV,EAAyB5D,KAAzB,CAAlB;AACA,qBAAOJ,aAAa,CAACiE,SAAD,CAAb,CAAyB3B,IAAzB,CAA8B,UAAArC,OAAO;AAAA,uBAC1C;AACA;AACAA,kBAAAA,OAAO,CAAC2C,MAAR,CAAe,UAACsB,GAAD,EAAM9D,KAAN,EAAgB;AAC7B8D,oBAAAA,GAAG,CAACC,GAAJ,CAAQ/D,KAAK,CAACZ,GAAd,EAAmBY,KAAnB;AACA,2BAAO8D,GAAP;AACD,mBAHD,EAGG,IAAIE,GAAJ,EAHH;AAH0C;AAAA,eAArC,EAOL9B,IAPK,CAOA,UAAA+B,OAAO,EAAI;AAChB;AADgB,2DAEIA,OAAO,CAACC,MAAR,EAFJ;AAAA;;AAAA;AAEhB,sEAAsC;AAAA,wBAA3BlE,MAA2B;AACpC,wBAAMmE,SAAS,GAAGxC,WAAW,CAACxC,KAAD,EAAQa,MAAR,CAA7B;AACA,wBAAImE,SAAJ,EACEf,MAAM,CAAC7B,KAAP,CAAa4C,SAAb;AACH;AANe;AAAA;AAAA;AAAA;AAAA;AAOjB,eAdM,EAcJhC,KAdI,CAcE,UAAAC,GAAG,EAAI;AACd,oBAAIA,GAAG,CAAC/C,IAAJ,KAAa,QAAjB,EACE,OAAOgD,SAAP;AACF,sBAAMD,GAAN;AACD,eAlBM,CAAP;AAmBD,aArBD,CADmD,CAAJ;AAAA,WAA1C,CAAP;AAwBD,SA5BD,CADmD,CAAJ;AAAA,OAA1C,CAAP;AA+BD,KAjCD,CADuC,CAAJ;AAAA,GAArC,EAoCGF,IApCH,CAqCI;AAAA,WAAMkB,MAAM,CAACgB,GAAP,EAAN;AAAA,GArCJ,EAsCI,UAAAhC,GAAG;AAAA,WAAIgB,MAAM,CAACiB,IAAP,CAAY,OAAZ,EAAqBjC,GAArB,CAAJ;AAAA,GAtCP;AAyCA,SAAOgB,MAAP;AACD;;AAEDpE,MAAM,CAACC,OAAP,CAAeqF,EAAf,GAAoBA,EAApB;;AAEA,SAASA,EAAT,CAAanF,KAAb,EAAoB;AAClB,SAAO8D,QAAQ,CAAC9D,KAAD,CAAR,CAAgBoF,OAAhB,GAA0BrC,IAA1B,CAA+B,UAAArC,OAAO;AAAA,WAC3CA,OAAO,CAAC2C,MAAR,CAAe,UAACsB,GAAD,EAAMU,EAAN,EAAa;AAC1BV,MAAAA,GAAG,CAACU,EAAE,CAACpF,GAAJ,CAAH,GAAcoF,EAAd;AACA,aAAOV,GAAP;AACD,KAHD,EAGG,EAHH,CAD2C;AAAA,GAAtC,CAAP;AAMD;;AAED9E,MAAM,CAACC,OAAP,CAAeW,aAAf,GAA+BA,aAA/B;;AAEA,SAASA,aAAT,CAAwBF,MAAxB,EAAgC+E,MAAhC,EAAwC;AACtC,SAAO5F,QAAQ,CAACa,MAAD,EAAS,MAAT,CAAR,CAAyBwC,IAAzB,CAA8B,UAACwC,IAAD;AAAA,WAAUC,cAAc,CAACD,IAAD,EAAOD,MAAP,CAAxB;AAAA,GAA9B,CAAP;AACD;;AAEDzF,MAAM,CAACC,OAAP,CAAeW,aAAf,CAA6BjB,IAA7B,GAAoCiE,iBAApC;;AAEA,SAASA,iBAAT,CAA4BlD,MAA5B,EAAoC+E,MAApC,EAA4C;AAC1C,MAAMC,IAAI,GAAG9G,EAAE,CAACgH,YAAH,CAAgBlF,MAAhB,EAAwB,MAAxB,CAAb;AACA,SAAOiF,cAAc,CAACD,IAAD,EAAOD,MAAP,CAArB;AACD;;AAED,SAASE,cAAT,CAAyBD,IAAzB,EAA+BD,MAA/B,EAAuC;AACrC,MAAM5E,OAAO,GAAG,EAAhB;AACA6E,EAAAA,IAAI,CAACG,KAAL,CAAW,IAAX,EAAiBC,OAAjB,CAAyB,UAAC9E,KAAD,EAAW;AAClC,QAAI,CAACA,KAAL,EACE;AAEF,QAAM+E,MAAM,GAAG/E,KAAK,CAAC6E,KAAN,CAAY,IAAZ,CAAf;;AACA,QAAI,CAACE,MAAM,CAAC,CAAD,CAAP,IAAclE,SAAS,CAACkE,MAAM,CAAC,CAAD,CAAP,CAAT,KAAyBA,MAAM,CAAC,CAAD,CAAjD,EAAsD;AACpD;AACA;AACA;AACD;;AACD,QAAIC,GAAJ;;AACA,QAAI;AACFA,MAAAA,GAAG,GAAGtE,IAAI,CAACuE,KAAL,CAAWF,MAAM,CAAC,CAAD,CAAjB,CAAN;AACD,KAFD,CAEE,OAAOG,CAAP,EAAU;AACV;AACA;AACD;;AACD,QAAIF,GAAJ,EACEnF,OAAO,CAACsF,IAAR,CAAaH,GAAb;AACH,GAnBD;AAoBA,SAAOnF,OAAP;AACD;;AAEDb,MAAM,CAACC,OAAP,CAAekE,SAAf,GAA2BA,SAA3B;;AAEA,SAASA,SAAT,CAAoBhE,KAApB,EAA2B;AACzB,SAAOrB,IAAI,CAACgD,IAAL,CAAU3B,KAAV,mBAA2Bd,MAA3B,EAAP;AACD;;AAEDW,MAAM,CAACC,OAAP,CAAeU,UAAf,GAA4BA,UAA5B;;AAEA,SAASA,UAAT,CAAqBR,KAArB,EAA4BC,GAA5B,EAAiC;AAC/B,MAAMgG,MAAM,GAAGC,OAAO,CAACjG,GAAD,CAAtB;AACA,SAAOtB,IAAI,CAACgD,IAAL,CAAUwE,KAAV,CACLxH,IADK,EAEL,CAACqF,SAAS,CAAChE,KAAD,CAAV,EAAmBoG,MAAnB,CAA0BnH,cAAc,CAACgH,MAAD,CAAxC,CAFK,CAAP;AAID;;AAEDpG,MAAM,CAACC,OAAP,CAAeoG,OAAf,GAAyBA,OAAzB;;AAEA,SAASA,OAAT,CAAkBjG,GAAlB,EAAuB;AACrB,SAAOwB,IAAI,CAACxB,GAAD,EAAM,QAAN,CAAX;AACD;;AAEDJ,MAAM,CAACC,OAAP,CAAe4B,SAAf,GAA2BA,SAA3B;;AAEA,SAASA,SAAT,CAAoB2E,GAApB,EAAyB;AACvB,SAAO5E,IAAI,CAAC4E,GAAD,EAAM,MAAN,CAAX;AACD;;AAED,SAAS5E,IAAT,CAAe4E,GAAf,EAAoBC,MAApB,EAA4B;AAC1B,SAAO9H,MAAM,CACV+H,UADI,CACOD,MADP,EAEJE,MAFI,CAEGH,GAFH,EAGJC,MAHI,CAGG,KAHH,CAAP;AAID;;AAED,SAAS9D,WAAT,CAAsBxC,KAAtB,EAA6Ba,KAA7B,EAAoC4F,OAApC,EAA6C;AAC3C;AACA,MAAI,CAAC5F,KAAK,CAACC,SAAP,IAAoB,CAAC2F,OAAzB,EACE,OAAO,IAAP;AAEF,SAAO;AACLxG,IAAAA,GAAG,EAAEY,KAAK,CAACZ,GADN;AAELa,IAAAA,SAAS,EAAED,KAAK,CAACC,SAFZ;AAGLnC,IAAAA,IAAI,EAAEkC,KAAK,CAACC,SAAN,GAAkB/B,WAAW,CAACiB,KAAD,EAAQa,KAAK,CAACC,SAAd,CAA7B,GAAwDoC,SAHzD;AAILP,IAAAA,IAAI,EAAE9B,KAAK,CAAC8B,IAJP;AAKLC,IAAAA,IAAI,EAAE/B,KAAK,CAAC+B,IALP;AAMLF,IAAAA,QAAQ,EAAE7B,KAAK,CAAC6B;AANX,GAAP;AAQD;;AAED,SAASyB,cAAT,CAAyBuC,GAAzB,EAA8B;AAC5B,SAAO/G,OAAO,CAAC+G,GAAD,CAAP,CAAa1D,KAAb,CAAmB,UAACC,GAAD,EAAS;AACjC,QAAIA,GAAG,CAAC/C,IAAJ,KAAa,QAAb,IAAyB+C,GAAG,CAAC/C,IAAJ,KAAa,SAA1C,EACE,OAAO,EAAP;AAEF,UAAM+C,GAAN;AACD,GALM,CAAP;AAMD","sourcesContent":["'use strict'\n\nconst util = require('util')\nconst crypto = require('crypto')\nconst fs = require('fs')\nconst Minipass = require('minipass')\nconst path = require('path')\nconst ssri = require('ssri')\nconst uniqueFilename = require('unique-filename')\n\nconst { disposer } = require('./util/disposer')\nconst contentPath = require('./content/path')\nconst fixOwner = require('./util/fix-owner')\nconst hashToSegments = require('./util/hash-to-segments')\nconst indexV = require('../package.json')['cache-version'].index\nconst moveFile = require('@npmcli/move-file')\nconst _rimraf = require('rimraf')\nconst rimraf = util.promisify(_rimraf)\nrimraf.sync = _rimraf.sync\n\nconst appendFile = util.promisify(fs.appendFile)\nconst readFile = util.promisify(fs.readFile)\nconst readdir = util.promisify(fs.readdir)\nconst writeFile = util.promisify(fs.writeFile)\n\nmodule.exports.NotFoundError = class NotFoundError extends Error {\n  constructor (cache, key) {\n    super(`No cache entry for ${key} found in ${cache}`)\n    this.code = 'ENOENT'\n    this.cache = cache\n    this.key = key\n  }\n}\n\nmodule.exports.compact = compact\n\nasync function compact (cache, key, matchFn, opts = {}) {\n  const bucket = bucketPath(cache, key)\n  const entries = await bucketEntries(bucket)\n  const newEntries = []\n  // we loop backwards because the bottom-most result is the newest\n  // since we add new entries with appendFile\n  for (let i = entries.length - 1; i >= 0; --i) {\n    const entry = entries[i]\n    // a null integrity could mean either a delete was appended\n    // or the user has simply stored an index that does not map\n    // to any content. we determine if the user wants to keep the\n    // null integrity based on the validateEntry function passed in options.\n    // if the integrity is null and no validateEntry is provided, we break\n    // as we consider the null integrity to be a deletion of everything\n    // that came before it.\n    if (entry.integrity === null && !opts.validateEntry)\n      break\n\n    // if this entry is valid, and it is either the first entry or\n    // the newEntries array doesn't already include an entry that\n    // matches this one based on the provided matchFn, then we add\n    // it to the beginning of our list\n    if ((!opts.validateEntry || opts.validateEntry(entry) === true) &&\n      (newEntries.length === 0 ||\n        !newEntries.find((oldEntry) => matchFn(oldEntry, entry))))\n      newEntries.unshift(entry)\n  }\n\n  const newIndex = '\\n' + newEntries.map((entry) => {\n    const stringified = JSON.stringify(entry)\n    const hash = hashEntry(stringified)\n    return `${hash}\\t${stringified}`\n  }).join('\\n')\n\n  const setup = async () => {\n    const target = uniqueFilename(path.join(cache, 'tmp'), opts.tmpPrefix)\n    await fixOwner.mkdirfix(cache, path.dirname(target))\n    return {\n      target,\n      moved: false,\n    }\n  }\n\n  const teardown = async (tmp) => {\n    if (!tmp.moved)\n      return rimraf(tmp.target)\n  }\n\n  const write = async (tmp) => {\n    await writeFile(tmp.target, newIndex, { flag: 'wx' })\n    await fixOwner.mkdirfix(cache, path.dirname(bucket))\n    // we use @npmcli/move-file directly here because we\n    // want to overwrite the existing file\n    await moveFile(tmp.target, bucket)\n    tmp.moved = true\n    try {\n      await fixOwner.chownr(cache, bucket)\n    } catch (err) {\n      if (err.code !== 'ENOENT')\n        throw err\n    }\n  }\n\n  // write the file atomically\n  await disposer(setup(), teardown, write)\n\n  // we reverse the list we generated such that the newest\n  // entries come first in order to make looping through them easier\n  // the true passed to formatEntry tells it to keep null\n  // integrity values, if they made it this far it's because\n  // validateEntry returned true, and as such we should return it\n  return newEntries.reverse().map((entry) => formatEntry(cache, entry, true))\n}\n\nmodule.exports.insert = insert\n\nfunction insert (cache, key, integrity, opts = {}) {\n  const { metadata, size } = opts\n  const bucket = bucketPath(cache, key)\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata,\n  }\n  return fixOwner\n    .mkdirfix(cache, path.dirname(bucket))\n    .then(() => {\n      const stringified = JSON.stringify(entry)\n      // NOTE - Cleverness ahoy!\n      //\n      // This works because it's tremendously unlikely for an entry to corrupt\n      // another while still preserving the string length of the JSON in\n      // question. So, we just slap the length in there and verify it on read.\n      //\n      // Thanks to @isaacs for the whiteboarding session that ended up with\n      // this.\n      return appendFile(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`)\n    })\n    .then(() => fixOwner.chownr(cache, bucket))\n    .catch((err) => {\n      if (err.code === 'ENOENT')\n        return undefined\n\n      throw err\n      // There's a class of race conditions that happen when things get deleted\n      // during fixOwner, or between the two mkdirfix/chownr calls.\n      //\n      // It's perfectly fine to just not bother in those cases and lie\n      // that the index entry was written. Because it's a cache.\n    })\n    .then(() => {\n      return formatEntry(cache, entry)\n    })\n}\n\nmodule.exports.insert.sync = insertSync\n\nfunction insertSync (cache, key, integrity, opts = {}) {\n  const { metadata, size } = opts\n  const bucket = bucketPath(cache, key)\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata,\n  }\n  fixOwner.mkdirfix.sync(cache, path.dirname(bucket))\n  const stringified = JSON.stringify(entry)\n  fs.appendFileSync(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`)\n  try {\n    fixOwner.chownr.sync(cache, bucket)\n  } catch (err) {\n    if (err.code !== 'ENOENT')\n      throw err\n  }\n  return formatEntry(cache, entry)\n}\n\nmodule.exports.find = find\n\nfunction find (cache, key) {\n  const bucket = bucketPath(cache, key)\n  return bucketEntries(bucket)\n    .then((entries) => {\n      return entries.reduce((latest, next) => {\n        if (next && next.key === key)\n          return formatEntry(cache, next)\n        else\n          return latest\n      }, null)\n    })\n    .catch((err) => {\n      if (err.code === 'ENOENT')\n        return null\n      else\n        throw err\n    })\n}\n\nmodule.exports.find.sync = findSync\n\nfunction findSync (cache, key) {\n  const bucket = bucketPath(cache, key)\n  try {\n    return bucketEntriesSync(bucket).reduce((latest, next) => {\n      if (next && next.key === key)\n        return formatEntry(cache, next)\n      else\n        return latest\n    }, null)\n  } catch (err) {\n    if (err.code === 'ENOENT')\n      return null\n    else\n      throw err\n  }\n}\n\nmodule.exports.delete = del\n\nfunction del (cache, key, opts = {}) {\n  if (!opts.removeFully)\n    return insert(cache, key, null, opts)\n\n  const bucket = bucketPath(cache, key)\n  return rimraf(bucket)\n}\n\nmodule.exports.delete.sync = delSync\n\nfunction delSync (cache, key, opts = {}) {\n  if (!opts.removeFully)\n    return insertSync(cache, key, null, opts)\n\n  const bucket = bucketPath(cache, key)\n  return rimraf.sync(bucket)\n}\n\nmodule.exports.lsStream = lsStream\n\nfunction lsStream (cache) {\n  const indexDir = bucketDir(cache)\n  const stream = new Minipass({ objectMode: true })\n\n  readdirOrEmpty(indexDir).then(buckets => Promise.all(\n    buckets.map(bucket => {\n      const bucketPath = path.join(indexDir, bucket)\n      return readdirOrEmpty(bucketPath).then(subbuckets => Promise.all(\n        subbuckets.map(subbucket => {\n          const subbucketPath = path.join(bucketPath, subbucket)\n\n          // \"/cachename/<bucket 0xFF>/<bucket 0xFF>./*\"\n          return readdirOrEmpty(subbucketPath).then(entries => Promise.all(\n            entries.map(entry => {\n              const entryPath = path.join(subbucketPath, entry)\n              return bucketEntries(entryPath).then(entries =>\n                // using a Map here prevents duplicate keys from\n                // showing up twice, I guess?\n                entries.reduce((acc, entry) => {\n                  acc.set(entry.key, entry)\n                  return acc\n                }, new Map())\n              ).then(reduced => {\n                // reduced is a map of key => entry\n                for (const entry of reduced.values()) {\n                  const formatted = formatEntry(cache, entry)\n                  if (formatted)\n                    stream.write(formatted)\n                }\n              }).catch(err => {\n                if (err.code === 'ENOENT')\n                  return undefined\n                throw err\n              })\n            })\n          ))\n        })\n      ))\n    })\n  ))\n    .then(\n      () => stream.end(),\n      err => stream.emit('error', err)\n    )\n\n  return stream\n}\n\nmodule.exports.ls = ls\n\nfunction ls (cache) {\n  return lsStream(cache).collect().then(entries =>\n    entries.reduce((acc, xs) => {\n      acc[xs.key] = xs\n      return acc\n    }, {})\n  )\n}\n\nmodule.exports.bucketEntries = bucketEntries\n\nfunction bucketEntries (bucket, filter) {\n  return readFile(bucket, 'utf8').then((data) => _bucketEntries(data, filter))\n}\n\nmodule.exports.bucketEntries.sync = bucketEntriesSync\n\nfunction bucketEntriesSync (bucket, filter) {\n  const data = fs.readFileSync(bucket, 'utf8')\n  return _bucketEntries(data, filter)\n}\n\nfunction _bucketEntries (data, filter) {\n  const entries = []\n  data.split('\\n').forEach((entry) => {\n    if (!entry)\n      return\n\n    const pieces = entry.split('\\t')\n    if (!pieces[1] || hashEntry(pieces[1]) !== pieces[0]) {\n      // Hash is no good! Corruption or malice? Doesn't matter!\n      // EJECT EJECT\n      return\n    }\n    let obj\n    try {\n      obj = JSON.parse(pieces[1])\n    } catch (e) {\n      // Entry is corrupted!\n      return\n    }\n    if (obj)\n      entries.push(obj)\n  })\n  return entries\n}\n\nmodule.exports.bucketDir = bucketDir\n\nfunction bucketDir (cache) {\n  return path.join(cache, `index-v${indexV}`)\n}\n\nmodule.exports.bucketPath = bucketPath\n\nfunction bucketPath (cache, key) {\n  const hashed = hashKey(key)\n  return path.join.apply(\n    path,\n    [bucketDir(cache)].concat(hashToSegments(hashed))\n  )\n}\n\nmodule.exports.hashKey = hashKey\n\nfunction hashKey (key) {\n  return hash(key, 'sha256')\n}\n\nmodule.exports.hashEntry = hashEntry\n\nfunction hashEntry (str) {\n  return hash(str, 'sha1')\n}\n\nfunction hash (str, digest) {\n  return crypto\n    .createHash(digest)\n    .update(str)\n    .digest('hex')\n}\n\nfunction formatEntry (cache, entry, keepAll) {\n  // Treat null digests as deletions. They'll shadow any previous entries.\n  if (!entry.integrity && !keepAll)\n    return null\n\n  return {\n    key: entry.key,\n    integrity: entry.integrity,\n    path: entry.integrity ? contentPath(cache, entry.integrity) : undefined,\n    size: entry.size,\n    time: entry.time,\n    metadata: entry.metadata,\n  }\n}\n\nfunction readdirOrEmpty (dir) {\n  return readdir(dir).catch((err) => {\n    if (err.code === 'ENOENT' || err.code === 'ENOTDIR')\n      return []\n\n    throw err\n  })\n}\n"]},"metadata":{},"sourceType":"script"}