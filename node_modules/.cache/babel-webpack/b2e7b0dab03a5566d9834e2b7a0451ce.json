{"ast":null,"code":"/*\n\tMIT License http://www.opensource.org/licenses/mit-license.php\n\tAuthor Tobias Koppers @sokra\n*/\n\"use strict\";\n\nvar _createForOfIteratorHelper = require(\"/Users/abdillahihussein/Documents/GitHub/angularProject/node_modules/@babel/runtime/helpers/createForOfIteratorHelper\");\n\nvar _classCallCheck = require(\"/Users/abdillahihussein/Documents/GitHub/angularProject/node_modules/@babel/runtime/helpers/classCallCheck\");\n\nvar _createClass = require(\"/Users/abdillahihussein/Documents/GitHub/angularProject/node_modules/@babel/runtime/helpers/createClass\");\n\nvar MergeDuplicateChunksPlugin = /*#__PURE__*/function () {\n  function MergeDuplicateChunksPlugin() {\n    _classCallCheck(this, MergeDuplicateChunksPlugin);\n  }\n\n  _createClass(MergeDuplicateChunksPlugin, [{\n    key: \"apply\",\n    value: function apply(compiler) {\n      compiler.hooks.compilation.tap(\"MergeDuplicateChunksPlugin\", function (compilation) {\n        compilation.hooks.optimizeChunksBasic.tap(\"MergeDuplicateChunksPlugin\", function (chunks) {\n          // remember already tested chunks for performance\n          var notDuplicates = new Set(); // for each chunk\n\n          var _iterator = _createForOfIteratorHelper(chunks),\n              _step;\n\n          try {\n            for (_iterator.s(); !(_step = _iterator.n()).done;) {\n              var chunk = _step.value;\n              // track a Set of all chunk that could be duplicates\n              var possibleDuplicates = void 0;\n\n              var _iterator2 = _createForOfIteratorHelper(chunk.modulesIterable),\n                  _step2;\n\n              try {\n                for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n                  var _module = _step2.value;\n\n                  if (possibleDuplicates === undefined) {\n                    // when possibleDuplicates is not yet set,\n                    // create a new Set from chunks of the current module\n                    // including only chunks with the same number of modules\n                    var _iterator4 = _createForOfIteratorHelper(_module.chunksIterable),\n                        _step4;\n\n                    try {\n                      for (_iterator4.s(); !(_step4 = _iterator4.n()).done;) {\n                        var dup = _step4.value;\n\n                        if (dup !== chunk && chunk.getNumberOfModules() === dup.getNumberOfModules() && !notDuplicates.has(dup)) {\n                          // delay allocating the new Set until here, reduce memory pressure\n                          if (possibleDuplicates === undefined) {\n                            possibleDuplicates = new Set();\n                          }\n\n                          possibleDuplicates.add(dup);\n                        }\n                      } // when no chunk is possible we can break here\n\n                    } catch (err) {\n                      _iterator4.e(err);\n                    } finally {\n                      _iterator4.f();\n                    }\n\n                    if (possibleDuplicates === undefined) break;\n                  } else {\n                    // validate existing possible duplicates\n                    var _iterator5 = _createForOfIteratorHelper(possibleDuplicates),\n                        _step5;\n\n                    try {\n                      for (_iterator5.s(); !(_step5 = _iterator5.n()).done;) {\n                        var _dup = _step5.value;\n\n                        // remove possible duplicate when module is not contained\n                        if (!_dup.containsModule(_module)) {\n                          possibleDuplicates.delete(_dup);\n                        }\n                      } // when all chunks has been removed we can break here\n\n                    } catch (err) {\n                      _iterator5.e(err);\n                    } finally {\n                      _iterator5.f();\n                    }\n\n                    if (possibleDuplicates.size === 0) break;\n                  }\n                } // when we found duplicates\n\n              } catch (err) {\n                _iterator2.e(err);\n              } finally {\n                _iterator2.f();\n              }\n\n              if (possibleDuplicates !== undefined && possibleDuplicates.size > 0) {\n                var _iterator3 = _createForOfIteratorHelper(possibleDuplicates),\n                    _step3;\n\n                try {\n                  for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n                    var otherChunk = _step3.value;\n                    if (otherChunk.hasRuntime() !== chunk.hasRuntime()) continue; // merge them\n\n                    if (chunk.integrate(otherChunk, \"duplicate\")) {\n                      chunks.splice(chunks.indexOf(otherChunk), 1);\n                    }\n                  }\n                } catch (err) {\n                  _iterator3.e(err);\n                } finally {\n                  _iterator3.f();\n                }\n              } // don't check already processed chunks twice\n\n\n              notDuplicates.add(chunk);\n            }\n          } catch (err) {\n            _iterator.e(err);\n          } finally {\n            _iterator.f();\n          }\n        });\n      });\n    }\n  }]);\n\n  return MergeDuplicateChunksPlugin;\n}();\n\nmodule.exports = MergeDuplicateChunksPlugin;","map":{"version":3,"sources":["/Users/abdillahihussein/Documents/GitHub/angularProject/node_modules/webpack/lib/optimize/MergeDuplicateChunksPlugin.js"],"names":["MergeDuplicateChunksPlugin","compiler","hooks","compilation","tap","optimizeChunksBasic","chunks","notDuplicates","Set","chunk","possibleDuplicates","modulesIterable","module","undefined","chunksIterable","dup","getNumberOfModules","has","add","containsModule","delete","size","otherChunk","hasRuntime","integrate","splice","indexOf","exports"],"mappings":"AAAA;AACA;AACA;AACA;AACA;;;;;;;;IAEMA,0B;;;;;;;WACL,eAAMC,QAAN,EAAgB;AACfA,MAAAA,QAAQ,CAACC,KAAT,CAAeC,WAAf,CAA2BC,GAA3B,CACC,4BADD,EAEC,UAAAD,WAAW,EAAI;AACdA,QAAAA,WAAW,CAACD,KAAZ,CAAkBG,mBAAlB,CAAsCD,GAAtC,CACC,4BADD,EAEC,UAAAE,MAAM,EAAI;AACT;AACA,cAAMC,aAAa,GAAG,IAAIC,GAAJ,EAAtB,CAFS,CAIT;;AAJS,qDAKWF,MALX;AAAA;;AAAA;AAKT,gEAA4B;AAAA,kBAAjBG,KAAiB;AAC3B;AACA,kBAAIC,kBAAkB,SAAtB;;AAF2B,0DAGND,KAAK,CAACE,eAHA;AAAA;;AAAA;AAG3B,uEAA4C;AAAA,sBAAjCC,OAAiC;;AAC3C,sBAAIF,kBAAkB,KAAKG,SAA3B,EAAsC;AACrC;AACA;AACA;AAHqC,gEAInBD,OAAM,CAACE,cAJY;AAAA;;AAAA;AAIrC,6EAAyC;AAAA,4BAA9BC,GAA8B;;AACxC,4BACCA,GAAG,KAAKN,KAAR,IACAA,KAAK,CAACO,kBAAN,OAA+BD,GAAG,CAACC,kBAAJ,EAD/B,IAEA,CAACT,aAAa,CAACU,GAAd,CAAkBF,GAAlB,CAHF,EAIE;AACD;AACA,8BAAIL,kBAAkB,KAAKG,SAA3B,EAAsC;AACrCH,4BAAAA,kBAAkB,GAAG,IAAIF,GAAJ,EAArB;AACA;;AACDE,0BAAAA,kBAAkB,CAACQ,GAAnB,CAAuBH,GAAvB;AACA;AACD,uBAhBoC,CAiBrC;;AAjBqC;AAAA;AAAA;AAAA;AAAA;;AAkBrC,wBAAIL,kBAAkB,KAAKG,SAA3B,EAAsC;AACtC,mBAnBD,MAmBO;AACN;AADM,gEAEYH,kBAFZ;AAAA;;AAAA;AAEN,6EAAsC;AAAA,4BAA3BK,IAA2B;;AACrC;AACA,4BAAI,CAACA,IAAG,CAACI,cAAJ,CAAmBP,OAAnB,CAAL,EAAiC;AAChCF,0BAAAA,kBAAkB,CAACU,MAAnB,CAA0BL,IAA1B;AACA;AACD,uBAPK,CAQN;;AARM;AAAA;AAAA;AAAA;AAAA;;AASN,wBAAIL,kBAAkB,CAACW,IAAnB,KAA4B,CAAhC,EAAmC;AACnC;AACD,iBAlC0B,CAoC3B;;AApC2B;AAAA;AAAA;AAAA;AAAA;;AAqC3B,kBACCX,kBAAkB,KAAKG,SAAvB,IACAH,kBAAkB,CAACW,IAAnB,GAA0B,CAF3B,EAGE;AAAA,4DACwBX,kBADxB;AAAA;;AAAA;AACD,yEAA6C;AAAA,wBAAlCY,UAAkC;AAC5C,wBAAIA,UAAU,CAACC,UAAX,OAA4Bd,KAAK,CAACc,UAAN,EAAhC,EAAoD,SADR,CAE5C;;AACA,wBAAId,KAAK,CAACe,SAAN,CAAgBF,UAAhB,EAA4B,WAA5B,CAAJ,EAA8C;AAC7ChB,sBAAAA,MAAM,CAACmB,MAAP,CAAcnB,MAAM,CAACoB,OAAP,CAAeJ,UAAf,CAAd,EAA0C,CAA1C;AACA;AACD;AAPA;AAAA;AAAA;AAAA;AAAA;AAQD,eAhD0B,CAkD3B;;;AACAf,cAAAA,aAAa,CAACW,GAAd,CAAkBT,KAAlB;AACA;AAzDQ;AAAA;AAAA;AAAA;AAAA;AA0DT,SA5DF;AA8DA,OAjEF;AAmEA;;;;;;AAEFG,MAAM,CAACe,OAAP,GAAiB3B,0BAAjB","sourcesContent":["/*\n\tMIT License http://www.opensource.org/licenses/mit-license.php\n\tAuthor Tobias Koppers @sokra\n*/\n\"use strict\";\n\nclass MergeDuplicateChunksPlugin {\n\tapply(compiler) {\n\t\tcompiler.hooks.compilation.tap(\n\t\t\t\"MergeDuplicateChunksPlugin\",\n\t\t\tcompilation => {\n\t\t\t\tcompilation.hooks.optimizeChunksBasic.tap(\n\t\t\t\t\t\"MergeDuplicateChunksPlugin\",\n\t\t\t\t\tchunks => {\n\t\t\t\t\t\t// remember already tested chunks for performance\n\t\t\t\t\t\tconst notDuplicates = new Set();\n\n\t\t\t\t\t\t// for each chunk\n\t\t\t\t\t\tfor (const chunk of chunks) {\n\t\t\t\t\t\t\t// track a Set of all chunk that could be duplicates\n\t\t\t\t\t\t\tlet possibleDuplicates;\n\t\t\t\t\t\t\tfor (const module of chunk.modulesIterable) {\n\t\t\t\t\t\t\t\tif (possibleDuplicates === undefined) {\n\t\t\t\t\t\t\t\t\t// when possibleDuplicates is not yet set,\n\t\t\t\t\t\t\t\t\t// create a new Set from chunks of the current module\n\t\t\t\t\t\t\t\t\t// including only chunks with the same number of modules\n\t\t\t\t\t\t\t\t\tfor (const dup of module.chunksIterable) {\n\t\t\t\t\t\t\t\t\t\tif (\n\t\t\t\t\t\t\t\t\t\t\tdup !== chunk &&\n\t\t\t\t\t\t\t\t\t\t\tchunk.getNumberOfModules() === dup.getNumberOfModules() &&\n\t\t\t\t\t\t\t\t\t\t\t!notDuplicates.has(dup)\n\t\t\t\t\t\t\t\t\t\t) {\n\t\t\t\t\t\t\t\t\t\t\t// delay allocating the new Set until here, reduce memory pressure\n\t\t\t\t\t\t\t\t\t\t\tif (possibleDuplicates === undefined) {\n\t\t\t\t\t\t\t\t\t\t\t\tpossibleDuplicates = new Set();\n\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\tpossibleDuplicates.add(dup);\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t// when no chunk is possible we can break here\n\t\t\t\t\t\t\t\t\tif (possibleDuplicates === undefined) break;\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t// validate existing possible duplicates\n\t\t\t\t\t\t\t\t\tfor (const dup of possibleDuplicates) {\n\t\t\t\t\t\t\t\t\t\t// remove possible duplicate when module is not contained\n\t\t\t\t\t\t\t\t\t\tif (!dup.containsModule(module)) {\n\t\t\t\t\t\t\t\t\t\t\tpossibleDuplicates.delete(dup);\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t// when all chunks has been removed we can break here\n\t\t\t\t\t\t\t\t\tif (possibleDuplicates.size === 0) break;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// when we found duplicates\n\t\t\t\t\t\t\tif (\n\t\t\t\t\t\t\t\tpossibleDuplicates !== undefined &&\n\t\t\t\t\t\t\t\tpossibleDuplicates.size > 0\n\t\t\t\t\t\t\t) {\n\t\t\t\t\t\t\t\tfor (const otherChunk of possibleDuplicates) {\n\t\t\t\t\t\t\t\t\tif (otherChunk.hasRuntime() !== chunk.hasRuntime()) continue;\n\t\t\t\t\t\t\t\t\t// merge them\n\t\t\t\t\t\t\t\t\tif (chunk.integrate(otherChunk, \"duplicate\")) {\n\t\t\t\t\t\t\t\t\t\tchunks.splice(chunks.indexOf(otherChunk), 1);\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// don't check already processed chunks twice\n\t\t\t\t\t\t\tnotDuplicates.add(chunk);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t);\n\t\t\t}\n\t\t);\n\t}\n}\nmodule.exports = MergeDuplicateChunksPlugin;\n"]},"metadata":{},"sourceType":"script"}